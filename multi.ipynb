{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import data_util\n",
    "import random\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/max/Downloads/real_cap/multi/pose/001_01.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/001_02.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/001_03.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/001_04.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/001_05.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/002_01.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/002_02.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/002_03.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/002_04.txt',\n",
       " '/home/max/Downloads/real_cap/multi/pose/002_05.txt']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob(os.path.join('/home/max/Downloads/real_cap/multi', 'pose', '*.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class each_object():\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 img_size=[512,512],\n",
    "                 num_inpt_views=4,\n",
    "                 num_trgt_views=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.num_inpt_views = num_inpt_views\n",
    "        self.num_trgt_views = num_trgt_views\n",
    "\n",
    "        self.color_dir = os.path.join(root_dir, 'rgb')\n",
    "        self.pose_dir = os.path.join(root_dir, 'pose')\n",
    "\n",
    "        if not os.path.isdir(self.color_dir):\n",
    "            print(\"Error! root dir is wrong\")\n",
    "            return\n",
    "\n",
    "        self.all_color = sorted(data_util.glob_imgs(self.color_dir))\n",
    "        self.all_poses = sorted(glob(os.path.join(self.pose_dir, '*.txt')))\n",
    "        \n",
    "        print(\"Buffering files...\")\n",
    "        self.all_views = []\n",
    "        for i in range(len(self.all_color)):\n",
    "            if not i % 10:\n",
    "                print(i)\n",
    "            self.all_views.append(self.read_view_tuple(i))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_color)//(self.num_inpt_views + self.num_trgt_views)\n",
    "        \n",
    "    def load_rgb(self, path):\n",
    "        img = data_util.load_img(path, square_crop=True, downsampling_order=1, target_size=self.img_size)\n",
    "        img = img[:, :, :3].astype(np.float32) / 255. - 0.5\n",
    "        img = img.transpose(2,0,1)\n",
    "        return img\n",
    "    \n",
    "    def read_view_tuple(self, idx):\n",
    "        gt_rgb = self.load_rgb(self.all_color[idx])\n",
    "        pose = data_util.load_pose(self.all_poses[idx])\n",
    "\n",
    "        this_view = {'gt_rgb': torch.from_numpy(gt_rgb),\n",
    "                     'pose': torch.from_numpy(pose)}\n",
    "        return this_view\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        inpt_views = self.all_views[idx*(self.num_inpt_views+self.num_trgt_views):\n",
    "                                    (idx+1)*self.num_inpt_views+idx*self.num_trgt_views]\n",
    "        inpt_views = random.sample(inpt_views, len(inpt_views))\n",
    "        trgt_views = self.all_views[(idx+1)*self.num_inpt_views+idx*self.num_trgt_views:\n",
    "                                   (idx+1)*(self.num_inpt_views+self.num_trgt_views)]\n",
    "\n",
    "        return inpt_views, trgt_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffering files...\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "root_dir = os.path.join('/home/max/Downloads/real_cap/multi')\n",
    "dataset = each_object(root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9529, -0.0231, -0.3024, 10.0801],\n",
      "         [-0.0430, -0.9973, -0.0593,  1.8792],\n",
      "         [-0.3002,  0.0695, -0.9513, -2.0421],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]])\n",
      "tensor([[[ 0.9998,  0.0153, -0.0146,  4.4225],\n",
      "         [ 0.0160, -0.9984,  0.0537, -0.2396],\n",
      "         [-0.0138, -0.0540, -0.9984,  0.4539],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "for inp,trt in dataloader:\n",
    "    print(trt[0]['pose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "for epoch in range(10):\n",
    "        for inpt_views, trgt_views in dataloader:\n",
    "            for i in range(len(inpt_views)):\n",
    "                assert inpt_views[i]['pose'].shape[0] == opt.batch_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
