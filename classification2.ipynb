{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import data_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_str = ['bench','cabinet','car','chair','gun','light','phone','plane','screen','ship','sofa','stereo','table']\n",
    "str2num = {label_str[i]:i for i in range(len(label_str))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, train=True):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        if train == True:\n",
    "            self.all_images = sorted(glob(os.path.join(root_dir, 'train_rgb', '*.png')))\n",
    "        if train == False:\n",
    "            self.all_images = sorted(glob(os.path.join(root_dir, 'test_rgb', '*.png')))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.all_images)        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_dir = self.all_images[idx]\n",
    "        image = data_util.load_img(image_dir, square_crop=True, downsampling_order=1, target_size=[256, 256])\n",
    "        image = image[:, :, :3].astype(np.float32) / 255. - 0.5\n",
    "        image = image.transpose(2,0,1)\n",
    "        image = torch.from_numpy(image)\n",
    "        \n",
    "        label = str2num[image_dir.split('/')[-1].split('_')[0]]\n",
    "        \n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(os.path.join('/home/max/classification_dataset'), True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "test_dataset = Dataset(os.path.join('/home/max/classification_dataset'), False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1):\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x,y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 20 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                \n",
    "        torch.save(model.state_dict(), os.path.join('/home/max/saved_data/classifier2/model_epoch'+str(e)+'.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size = 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size = 3, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(32, 32, kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(32*8*8, 64)\n",
    "        self.fc2 = nn.Linear(64, 13)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, padding=0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv4(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv5(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = out.view(out.shape[0],-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        scores = self.fc2(out)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.6312\n",
      "Iteration 20, loss = 2.5659\n",
      "Iteration 40, loss = 2.5343\n",
      "Iteration 60, loss = 2.5889\n",
      "Iteration 80, loss = 2.5087\n",
      "Iteration 100, loss = 2.5262\n",
      "Iteration 120, loss = 2.5913\n",
      "Iteration 140, loss = 2.5352\n",
      "Iteration 160, loss = 2.5523\n",
      "Iteration 180, loss = 2.4088\n",
      "Iteration 200, loss = 2.5669\n",
      "Iteration 220, loss = 2.4198\n",
      "Iteration 240, loss = 1.5887\n",
      "Iteration 260, loss = 2.6147\n",
      "Iteration 280, loss = 2.2683\n",
      "Iteration 300, loss = 1.9307\n",
      "Iteration 320, loss = 1.7122\n",
      "Iteration 340, loss = 1.3170\n",
      "Iteration 360, loss = 1.8489\n",
      "Iteration 380, loss = 1.0947\n",
      "Iteration 400, loss = 1.2103\n",
      "Iteration 420, loss = 2.5032\n",
      "Iteration 440, loss = 1.1465\n",
      "Iteration 460, loss = 1.5404\n",
      "Iteration 480, loss = 1.0071\n",
      "Iteration 500, loss = 1.4545\n",
      "Iteration 520, loss = 1.4662\n",
      "Iteration 540, loss = 1.2535\n",
      "Iteration 560, loss = 1.4909\n",
      "Iteration 580, loss = 1.5115\n",
      "Iteration 600, loss = 1.2997\n",
      "Iteration 620, loss = 1.4619\n",
      "Iteration 640, loss = 1.4997\n",
      "Iteration 660, loss = 0.8429\n",
      "Iteration 680, loss = 1.8212\n",
      "Iteration 700, loss = 0.7690\n",
      "Iteration 720, loss = 2.6208\n",
      "Iteration 740, loss = 1.4904\n",
      "Iteration 760, loss = 1.7846\n",
      "Iteration 780, loss = 0.7466\n",
      "Iteration 800, loss = 0.9919\n",
      "Iteration 820, loss = 1.3360\n",
      "Iteration 0, loss = 0.8281\n",
      "Iteration 20, loss = 1.7854\n",
      "Iteration 40, loss = 0.7195\n",
      "Iteration 60, loss = 1.2910\n",
      "Iteration 80, loss = 0.6155\n",
      "Iteration 100, loss = 1.6189\n",
      "Iteration 120, loss = 1.1104\n",
      "Iteration 140, loss = 0.7347\n",
      "Iteration 160, loss = 2.4869\n",
      "Iteration 180, loss = 0.5993\n",
      "Iteration 200, loss = 1.0949\n",
      "Iteration 220, loss = 1.6214\n",
      "Iteration 240, loss = 0.7634\n",
      "Iteration 260, loss = 1.0455\n",
      "Iteration 280, loss = 0.8163\n",
      "Iteration 300, loss = 1.0808\n",
      "Iteration 320, loss = 0.9457\n",
      "Iteration 340, loss = 1.2301\n",
      "Iteration 360, loss = 3.6508\n",
      "Iteration 380, loss = 1.2592\n",
      "Iteration 400, loss = 1.7270\n",
      "Iteration 420, loss = 1.2596\n",
      "Iteration 440, loss = 0.8928\n",
      "Iteration 460, loss = 1.0526\n",
      "Iteration 480, loss = 1.8517\n",
      "Iteration 500, loss = 1.5063\n",
      "Iteration 520, loss = 0.6903\n",
      "Iteration 540, loss = 0.7598\n",
      "Iteration 560, loss = 0.6375\n",
      "Iteration 580, loss = 1.2020\n",
      "Iteration 600, loss = 0.8083\n",
      "Iteration 620, loss = 0.5319\n",
      "Iteration 640, loss = 1.5957\n",
      "Iteration 660, loss = 1.0673\n",
      "Iteration 680, loss = 0.7428\n",
      "Iteration 700, loss = 0.5780\n",
      "Iteration 720, loss = 0.2626\n",
      "Iteration 740, loss = 2.1168\n",
      "Iteration 760, loss = 1.0947\n",
      "Iteration 780, loss = 0.2921\n",
      "Iteration 800, loss = 1.2216\n",
      "Iteration 820, loss = 1.9951\n",
      "Iteration 0, loss = 0.7445\n",
      "Iteration 20, loss = 0.6924\n",
      "Iteration 40, loss = 0.9586\n",
      "Iteration 60, loss = 0.3483\n",
      "Iteration 80, loss = 0.7191\n",
      "Iteration 100, loss = 1.1302\n",
      "Iteration 120, loss = 0.2924\n",
      "Iteration 140, loss = 0.8447\n",
      "Iteration 160, loss = 0.2802\n",
      "Iteration 180, loss = 0.7096\n",
      "Iteration 200, loss = 0.6932\n",
      "Iteration 220, loss = 0.6296\n",
      "Iteration 240, loss = 0.1038\n",
      "Iteration 260, loss = 0.8012\n",
      "Iteration 280, loss = 0.5949\n",
      "Iteration 300, loss = 0.4208\n",
      "Iteration 320, loss = 0.6061\n",
      "Iteration 340, loss = 0.1059\n",
      "Iteration 360, loss = 1.1603\n",
      "Iteration 380, loss = 0.1547\n",
      "Iteration 400, loss = 1.3071\n",
      "Iteration 420, loss = 1.8407\n",
      "Iteration 440, loss = 1.6606\n",
      "Iteration 460, loss = 0.6199\n",
      "Iteration 480, loss = 1.2412\n",
      "Iteration 500, loss = 1.3487\n",
      "Iteration 520, loss = 1.4656\n",
      "Iteration 540, loss = 0.5047\n",
      "Iteration 560, loss = 0.8282\n",
      "Iteration 580, loss = 0.8702\n",
      "Iteration 600, loss = 1.7802\n",
      "Iteration 620, loss = 1.0883\n",
      "Iteration 640, loss = 1.6308\n",
      "Iteration 660, loss = 0.8407\n",
      "Iteration 680, loss = 0.5688\n",
      "Iteration 700, loss = 0.4966\n",
      "Iteration 720, loss = 1.4904\n",
      "Iteration 740, loss = 1.3052\n",
      "Iteration 760, loss = 0.4219\n",
      "Iteration 780, loss = 1.5792\n",
      "Iteration 800, loss = 1.0722\n",
      "Iteration 820, loss = 0.4160\n",
      "Iteration 0, loss = 0.4195\n",
      "Iteration 20, loss = 0.8839\n",
      "Iteration 40, loss = 0.8425\n",
      "Iteration 60, loss = 0.5779\n",
      "Iteration 80, loss = 0.5997\n",
      "Iteration 100, loss = 0.3059\n",
      "Iteration 120, loss = 0.2157\n",
      "Iteration 140, loss = 0.5257\n",
      "Iteration 160, loss = 1.3505\n",
      "Iteration 180, loss = 1.1674\n",
      "Iteration 200, loss = 0.3273\n",
      "Iteration 220, loss = 0.7698\n",
      "Iteration 240, loss = 1.1424\n",
      "Iteration 260, loss = 0.2288\n",
      "Iteration 280, loss = 0.2762\n",
      "Iteration 300, loss = 0.6628\n",
      "Iteration 320, loss = 0.2760\n",
      "Iteration 340, loss = 0.7393\n",
      "Iteration 360, loss = 1.1705\n",
      "Iteration 380, loss = 1.1093\n",
      "Iteration 400, loss = 0.6199\n",
      "Iteration 420, loss = 0.2926\n",
      "Iteration 440, loss = 0.1791\n",
      "Iteration 460, loss = 0.5826\n",
      "Iteration 480, loss = 0.3629\n",
      "Iteration 500, loss = 0.7966\n",
      "Iteration 520, loss = 0.5576\n",
      "Iteration 540, loss = 0.4102\n",
      "Iteration 560, loss = 1.0259\n",
      "Iteration 580, loss = 0.3841\n",
      "Iteration 600, loss = 1.3239\n",
      "Iteration 620, loss = 0.1733\n",
      "Iteration 640, loss = 0.6311\n",
      "Iteration 660, loss = 0.4971\n",
      "Iteration 680, loss = 1.0536\n",
      "Iteration 700, loss = 0.5627\n",
      "Iteration 720, loss = 0.1080\n",
      "Iteration 740, loss = 0.4892\n",
      "Iteration 760, loss = 0.2110\n",
      "Iteration 780, loss = 1.1022\n",
      "Iteration 800, loss = 0.6048\n",
      "Iteration 820, loss = 0.9671\n",
      "Iteration 0, loss = 0.6443\n",
      "Iteration 20, loss = 0.2534\n",
      "Iteration 40, loss = 0.6516\n",
      "Iteration 60, loss = 0.1526\n",
      "Iteration 80, loss = 1.1754\n",
      "Iteration 100, loss = 1.2040\n",
      "Iteration 120, loss = 0.8838\n",
      "Iteration 140, loss = 1.4801\n",
      "Iteration 160, loss = 0.2305\n",
      "Iteration 180, loss = 1.0077\n",
      "Iteration 200, loss = 0.6366\n",
      "Iteration 220, loss = 0.8472\n",
      "Iteration 240, loss = 0.4381\n",
      "Iteration 260, loss = 0.1030\n",
      "Iteration 280, loss = 1.2389\n",
      "Iteration 300, loss = 0.0690\n",
      "Iteration 320, loss = 0.1329\n",
      "Iteration 340, loss = 0.4375\n",
      "Iteration 360, loss = 0.3737\n",
      "Iteration 380, loss = 0.4133\n",
      "Iteration 400, loss = 1.2445\n",
      "Iteration 420, loss = 0.3746\n",
      "Iteration 440, loss = 0.2751\n",
      "Iteration 460, loss = 0.1817\n",
      "Iteration 480, loss = 0.3999\n",
      "Iteration 500, loss = 0.1102\n",
      "Iteration 520, loss = 0.4295\n",
      "Iteration 540, loss = 0.2803\n",
      "Iteration 560, loss = 0.0494\n",
      "Iteration 580, loss = 1.1819\n",
      "Iteration 600, loss = 0.6964\n",
      "Iteration 620, loss = 1.0404\n",
      "Iteration 640, loss = 0.3575\n",
      "Iteration 660, loss = 0.3629\n",
      "Iteration 680, loss = 0.2069\n",
      "Iteration 700, loss = 2.1072\n",
      "Iteration 720, loss = 0.6153\n",
      "Iteration 740, loss = 1.7103\n",
      "Iteration 760, loss = 0.7880\n",
      "Iteration 780, loss = 0.0420\n",
      "Iteration 800, loss = 0.8760\n",
      "Iteration 820, loss = 1.0802\n",
      "Iteration 0, loss = 0.0352\n",
      "Iteration 20, loss = 0.1574\n",
      "Iteration 40, loss = 0.5190\n",
      "Iteration 60, loss = 1.3577\n",
      "Iteration 80, loss = 0.7929\n",
      "Iteration 100, loss = 0.5486\n",
      "Iteration 120, loss = 0.5447\n",
      "Iteration 140, loss = 0.0088\n",
      "Iteration 160, loss = 0.6982\n",
      "Iteration 180, loss = 0.0586\n",
      "Iteration 200, loss = 0.2993\n",
      "Iteration 220, loss = 0.6796\n",
      "Iteration 240, loss = 0.2600\n",
      "Iteration 260, loss = 0.4912\n",
      "Iteration 280, loss = 0.6252\n",
      "Iteration 300, loss = 0.1573\n",
      "Iteration 320, loss = 0.1261\n",
      "Iteration 340, loss = 0.0945\n",
      "Iteration 360, loss = 0.3565\n",
      "Iteration 380, loss = 0.8926\n",
      "Iteration 400, loss = 0.6565\n",
      "Iteration 420, loss = 0.0299\n",
      "Iteration 440, loss = 0.7811\n",
      "Iteration 460, loss = 0.1694\n",
      "Iteration 480, loss = 0.8304\n",
      "Iteration 500, loss = 0.0507\n",
      "Iteration 520, loss = 0.1672\n",
      "Iteration 540, loss = 0.0734\n",
      "Iteration 560, loss = 0.8899\n",
      "Iteration 580, loss = 0.4993\n",
      "Iteration 600, loss = 0.4644\n",
      "Iteration 620, loss = 0.8144\n",
      "Iteration 640, loss = 0.3741\n",
      "Iteration 660, loss = 0.1821\n",
      "Iteration 680, loss = 0.1089\n",
      "Iteration 700, loss = 0.0958\n",
      "Iteration 720, loss = 0.0814\n",
      "Iteration 740, loss = 1.2446\n",
      "Iteration 760, loss = 0.6550\n",
      "Iteration 780, loss = 0.7875\n",
      "Iteration 800, loss = 0.4137\n",
      "Iteration 820, loss = 0.6467\n",
      "Iteration 0, loss = 0.3868\n",
      "Iteration 20, loss = 0.5310\n",
      "Iteration 40, loss = 0.2838\n",
      "Iteration 60, loss = 0.1430\n",
      "Iteration 80, loss = 0.0633\n",
      "Iteration 100, loss = 0.2160\n",
      "Iteration 120, loss = 0.2533\n",
      "Iteration 140, loss = 0.5602\n",
      "Iteration 160, loss = 0.0041\n",
      "Iteration 180, loss = 0.3482\n",
      "Iteration 200, loss = 0.0100\n",
      "Iteration 220, loss = 0.2188\n",
      "Iteration 240, loss = 0.5899\n",
      "Iteration 260, loss = 0.1647\n",
      "Iteration 280, loss = 0.9100\n",
      "Iteration 300, loss = 0.0130\n",
      "Iteration 320, loss = 0.2655\n",
      "Iteration 340, loss = 0.0304\n",
      "Iteration 360, loss = 0.7665\n",
      "Iteration 380, loss = 0.4523\n",
      "Iteration 400, loss = 0.3638\n",
      "Iteration 420, loss = 0.0469\n",
      "Iteration 440, loss = 0.0029\n",
      "Iteration 460, loss = 0.7924\n",
      "Iteration 480, loss = 0.6023\n",
      "Iteration 500, loss = 0.7604\n",
      "Iteration 520, loss = 0.0243\n",
      "Iteration 540, loss = 0.1158\n",
      "Iteration 560, loss = 0.0456\n",
      "Iteration 580, loss = 0.0525\n",
      "Iteration 600, loss = 0.0077\n",
      "Iteration 620, loss = 0.0799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 640, loss = 0.3809\n",
      "Iteration 660, loss = 0.2236\n",
      "Iteration 680, loss = 0.0487\n",
      "Iteration 700, loss = 0.2145\n",
      "Iteration 720, loss = 0.5467\n",
      "Iteration 740, loss = 0.4188\n",
      "Iteration 760, loss = 0.7424\n",
      "Iteration 780, loss = 0.0556\n",
      "Iteration 800, loss = 0.1578\n",
      "Iteration 820, loss = 0.1488\n",
      "Iteration 0, loss = 0.1497\n",
      "Iteration 20, loss = 0.2725\n",
      "Iteration 40, loss = 0.0006\n",
      "Iteration 60, loss = 0.1483\n",
      "Iteration 80, loss = 0.4220\n",
      "Iteration 100, loss = 0.2539\n",
      "Iteration 120, loss = 1.1014\n",
      "Iteration 140, loss = 0.7071\n",
      "Iteration 160, loss = 0.3934\n",
      "Iteration 180, loss = 0.5646\n",
      "Iteration 200, loss = 0.2844\n",
      "Iteration 220, loss = 0.0048\n",
      "Iteration 240, loss = 0.0188\n",
      "Iteration 260, loss = 1.1212\n",
      "Iteration 280, loss = 0.0856\n",
      "Iteration 300, loss = 0.0191\n",
      "Iteration 320, loss = 0.4627\n",
      "Iteration 340, loss = 0.7126\n",
      "Iteration 360, loss = 0.4704\n",
      "Iteration 380, loss = 0.1070\n",
      "Iteration 400, loss = 0.3543\n",
      "Iteration 420, loss = 0.8160\n",
      "Iteration 440, loss = 0.6449\n",
      "Iteration 460, loss = 0.2950\n",
      "Iteration 480, loss = 0.0470\n",
      "Iteration 500, loss = 0.2717\n",
      "Iteration 520, loss = 0.2994\n",
      "Iteration 540, loss = 0.3405\n",
      "Iteration 560, loss = 0.2297\n",
      "Iteration 580, loss = 0.7223\n",
      "Iteration 600, loss = 0.0181\n",
      "Iteration 620, loss = 0.3128\n",
      "Iteration 640, loss = 0.1379\n",
      "Iteration 660, loss = 0.0765\n",
      "Iteration 680, loss = 0.0630\n",
      "Iteration 700, loss = 0.1953\n",
      "Iteration 720, loss = 0.7050\n",
      "Iteration 740, loss = 0.3003\n",
      "Iteration 760, loss = 0.2307\n",
      "Iteration 780, loss = 0.0401\n",
      "Iteration 800, loss = 0.0730\n",
      "Iteration 820, loss = 0.3862\n",
      "Iteration 0, loss = 0.3828\n",
      "Iteration 20, loss = 0.1341\n",
      "Iteration 40, loss = 0.0803\n",
      "Iteration 60, loss = 0.0803\n",
      "Iteration 80, loss = 0.0308\n",
      "Iteration 100, loss = 0.0614\n",
      "Iteration 120, loss = 0.0871\n",
      "Iteration 140, loss = 0.0313\n",
      "Iteration 160, loss = 0.3030\n",
      "Iteration 180, loss = 0.5652\n",
      "Iteration 200, loss = 0.0214\n",
      "Iteration 220, loss = 0.0207\n",
      "Iteration 240, loss = 0.1762\n",
      "Iteration 260, loss = 0.1391\n",
      "Iteration 280, loss = 0.2904\n",
      "Iteration 300, loss = 0.7584\n",
      "Iteration 320, loss = 0.0092\n",
      "Iteration 340, loss = 0.0303\n",
      "Iteration 360, loss = 0.0713\n",
      "Iteration 380, loss = 0.0187\n",
      "Iteration 400, loss = 0.0135\n",
      "Iteration 420, loss = 0.3424\n",
      "Iteration 440, loss = 0.0134\n",
      "Iteration 460, loss = 0.7938\n",
      "Iteration 480, loss = 0.0206\n",
      "Iteration 500, loss = 0.0616\n",
      "Iteration 520, loss = 0.0362\n",
      "Iteration 540, loss = 0.0066\n",
      "Iteration 560, loss = 0.0234\n",
      "Iteration 580, loss = 0.1742\n",
      "Iteration 600, loss = 0.0960\n",
      "Iteration 620, loss = 0.0070\n",
      "Iteration 640, loss = 0.0314\n",
      "Iteration 660, loss = 0.2379\n",
      "Iteration 680, loss = 0.8587\n",
      "Iteration 700, loss = 0.6649\n",
      "Iteration 720, loss = 0.3950\n",
      "Iteration 740, loss = 0.0359\n",
      "Iteration 760, loss = 0.0444\n",
      "Iteration 780, loss = 0.1442\n",
      "Iteration 800, loss = 0.2787\n",
      "Iteration 820, loss = 0.1650\n",
      "Iteration 0, loss = 0.0060\n",
      "Iteration 20, loss = 0.0106\n",
      "Iteration 40, loss = 0.1029\n",
      "Iteration 60, loss = 0.2675\n",
      "Iteration 80, loss = 0.0134\n",
      "Iteration 100, loss = 0.1229\n",
      "Iteration 120, loss = 0.0072\n",
      "Iteration 140, loss = 0.0007\n",
      "Iteration 160, loss = 0.2281\n",
      "Iteration 180, loss = 0.0327\n",
      "Iteration 200, loss = 0.1432\n",
      "Iteration 220, loss = 0.0828\n",
      "Iteration 240, loss = 0.3788\n",
      "Iteration 260, loss = 0.0446\n",
      "Iteration 280, loss = 0.0203\n",
      "Iteration 300, loss = 0.4872\n",
      "Iteration 320, loss = 0.3094\n",
      "Iteration 340, loss = 0.1815\n",
      "Iteration 360, loss = 0.1038\n",
      "Iteration 380, loss = 0.0551\n",
      "Iteration 400, loss = 0.0848\n",
      "Iteration 420, loss = 0.0971\n",
      "Iteration 440, loss = 0.0037\n",
      "Iteration 460, loss = 0.0511\n",
      "Iteration 480, loss = 0.9450\n",
      "Iteration 500, loss = 0.1626\n",
      "Iteration 520, loss = 0.4080\n",
      "Iteration 540, loss = 0.0036\n",
      "Iteration 560, loss = 0.0352\n",
      "Iteration 580, loss = 0.4597\n",
      "Iteration 600, loss = 0.3747\n",
      "Iteration 620, loss = 0.0015\n",
      "Iteration 640, loss = 0.0209\n",
      "Iteration 660, loss = 0.0455\n",
      "Iteration 680, loss = 0.2585\n",
      "Iteration 700, loss = 0.1528\n",
      "Iteration 720, loss = 0.0013\n",
      "Iteration 740, loss = 0.3632\n",
      "Iteration 760, loss = 0.3032\n",
      "Iteration 780, loss = 0.0195\n",
      "Iteration 800, loss = 0.0037\n",
      "Iteration 820, loss = 0.0351\n",
      "Iteration 0, loss = 0.0219\n",
      "Iteration 20, loss = 0.0929\n",
      "Iteration 40, loss = 0.2528\n",
      "Iteration 60, loss = 0.0518\n",
      "Iteration 80, loss = 0.0613\n",
      "Iteration 100, loss = 0.1300\n",
      "Iteration 120, loss = 0.0011\n",
      "Iteration 140, loss = 0.0054\n",
      "Iteration 160, loss = 0.0249\n",
      "Iteration 180, loss = 0.0001\n",
      "Iteration 200, loss = 0.1482\n",
      "Iteration 220, loss = 0.0727\n",
      "Iteration 240, loss = 0.1924\n",
      "Iteration 260, loss = 0.0000\n",
      "Iteration 280, loss = 0.1161\n",
      "Iteration 300, loss = 0.0002\n",
      "Iteration 320, loss = 0.1444\n",
      "Iteration 340, loss = 0.0311\n",
      "Iteration 360, loss = 0.0311\n",
      "Iteration 380, loss = 0.0020\n",
      "Iteration 400, loss = 0.0212\n",
      "Iteration 420, loss = 0.0008\n",
      "Iteration 440, loss = 0.0203\n",
      "Iteration 460, loss = 0.0151\n",
      "Iteration 480, loss = 0.3777\n",
      "Iteration 500, loss = 0.2235\n",
      "Iteration 520, loss = 0.0364\n",
      "Iteration 540, loss = 0.0163\n",
      "Iteration 560, loss = 0.0139\n",
      "Iteration 580, loss = 0.0013\n",
      "Iteration 600, loss = 0.9677\n",
      "Iteration 620, loss = 0.3968\n",
      "Iteration 640, loss = 0.0413\n",
      "Iteration 660, loss = 0.2784\n",
      "Iteration 680, loss = 0.0001\n",
      "Iteration 700, loss = 0.4069\n",
      "Iteration 720, loss = 0.0721\n",
      "Iteration 740, loss = 0.6324\n",
      "Iteration 760, loss = 0.4300\n",
      "Iteration 780, loss = 0.1209\n",
      "Iteration 800, loss = 0.2012\n",
      "Iteration 820, loss = 0.1600\n",
      "Iteration 0, loss = 0.0017\n",
      "Iteration 20, loss = 0.1679\n",
      "Iteration 40, loss = 0.2500\n",
      "Iteration 60, loss = 0.0052\n",
      "Iteration 80, loss = 0.0039\n",
      "Iteration 100, loss = 0.3574\n",
      "Iteration 120, loss = 0.0001\n",
      "Iteration 140, loss = 0.1181\n",
      "Iteration 160, loss = 0.0089\n",
      "Iteration 180, loss = 0.0412\n",
      "Iteration 200, loss = 0.0137\n",
      "Iteration 220, loss = 0.1906\n",
      "Iteration 240, loss = 0.1055\n",
      "Iteration 260, loss = 0.0017\n",
      "Iteration 280, loss = 0.0191\n",
      "Iteration 300, loss = 0.3761\n",
      "Iteration 320, loss = 0.0016\n",
      "Iteration 340, loss = 1.0919\n",
      "Iteration 360, loss = 0.1178\n",
      "Iteration 380, loss = 0.1794\n",
      "Iteration 400, loss = 0.2268\n",
      "Iteration 420, loss = 0.0733\n",
      "Iteration 440, loss = 0.0047\n",
      "Iteration 460, loss = 0.0023\n",
      "Iteration 480, loss = 0.0507\n",
      "Iteration 500, loss = 0.0067\n",
      "Iteration 520, loss = 0.0013\n",
      "Iteration 540, loss = 0.0405\n",
      "Iteration 560, loss = 0.2750\n",
      "Iteration 580, loss = 0.3584\n",
      "Iteration 600, loss = 0.1807\n",
      "Iteration 620, loss = 0.1925\n",
      "Iteration 640, loss = 0.0029\n",
      "Iteration 660, loss = 0.5943\n",
      "Iteration 680, loss = 0.4060\n",
      "Iteration 700, loss = 0.0228\n",
      "Iteration 720, loss = 0.0067\n",
      "Iteration 740, loss = 0.1227\n",
      "Iteration 760, loss = 0.1130\n",
      "Iteration 780, loss = 0.0075\n",
      "Iteration 800, loss = 0.0007\n",
      "Iteration 820, loss = 1.0433\n",
      "Iteration 0, loss = 0.0370\n",
      "Iteration 20, loss = 0.0043\n",
      "Iteration 40, loss = 0.0163\n",
      "Iteration 60, loss = 0.0092\n",
      "Iteration 80, loss = 0.0196\n",
      "Iteration 100, loss = 0.0651\n",
      "Iteration 120, loss = 0.0981\n",
      "Iteration 140, loss = 0.0623\n",
      "Iteration 160, loss = 0.5457\n",
      "Iteration 180, loss = 0.2250\n",
      "Iteration 200, loss = 0.1943\n",
      "Iteration 220, loss = 0.0012\n",
      "Iteration 240, loss = 0.0001\n",
      "Iteration 260, loss = 0.0011\n",
      "Iteration 280, loss = 0.0342\n",
      "Iteration 300, loss = 0.0075\n",
      "Iteration 320, loss = 0.1837\n",
      "Iteration 340, loss = 0.0069\n",
      "Iteration 360, loss = 0.0003\n",
      "Iteration 380, loss = 0.5853\n",
      "Iteration 400, loss = 0.0010\n",
      "Iteration 420, loss = 0.0037\n",
      "Iteration 440, loss = 0.0739\n",
      "Iteration 460, loss = 0.0081\n",
      "Iteration 480, loss = 0.0426\n",
      "Iteration 500, loss = 0.1124\n",
      "Iteration 520, loss = 0.1557\n",
      "Iteration 540, loss = 0.0413\n",
      "Iteration 560, loss = 0.1075\n",
      "Iteration 580, loss = 0.5129\n",
      "Iteration 600, loss = 0.0516\n",
      "Iteration 620, loss = 0.0145\n",
      "Iteration 640, loss = 0.0033\n",
      "Iteration 660, loss = 0.0020\n",
      "Iteration 680, loss = 0.0122\n",
      "Iteration 700, loss = 0.0187\n",
      "Iteration 720, loss = 0.1312\n",
      "Iteration 740, loss = 0.1822\n",
      "Iteration 760, loss = 0.0057\n",
      "Iteration 780, loss = 0.0245\n",
      "Iteration 800, loss = 0.0041\n",
      "Iteration 820, loss = 0.1031\n",
      "Iteration 0, loss = 0.0085\n",
      "Iteration 20, loss = 0.0568\n",
      "Iteration 40, loss = 0.0089\n",
      "Iteration 60, loss = 0.0020\n",
      "Iteration 80, loss = 0.0026\n",
      "Iteration 100, loss = 0.9759\n",
      "Iteration 120, loss = 0.0016\n",
      "Iteration 140, loss = 0.0131\n",
      "Iteration 160, loss = 0.5763\n",
      "Iteration 180, loss = 0.0141\n",
      "Iteration 200, loss = 0.3123\n",
      "Iteration 220, loss = 0.1694\n",
      "Iteration 240, loss = 0.0293\n",
      "Iteration 260, loss = 0.3975\n",
      "Iteration 280, loss = 0.1471\n",
      "Iteration 300, loss = 0.1160\n",
      "Iteration 320, loss = 0.0005\n",
      "Iteration 340, loss = 0.2671\n",
      "Iteration 360, loss = 0.0755\n",
      "Iteration 380, loss = 0.0029\n",
      "Iteration 400, loss = 0.0148\n",
      "Iteration 420, loss = 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 440, loss = 0.0021\n",
      "Iteration 460, loss = 0.0697\n",
      "Iteration 480, loss = 0.0016\n",
      "Iteration 500, loss = 0.0009\n",
      "Iteration 520, loss = 0.1520\n",
      "Iteration 540, loss = 0.2117\n",
      "Iteration 560, loss = 0.0023\n",
      "Iteration 580, loss = 0.0065\n",
      "Iteration 600, loss = 0.0082\n",
      "Iteration 620, loss = 0.1918\n",
      "Iteration 640, loss = 0.0168\n",
      "Iteration 660, loss = 0.0095\n",
      "Iteration 680, loss = 0.0207\n",
      "Iteration 700, loss = 0.1416\n",
      "Iteration 720, loss = 0.0373\n",
      "Iteration 740, loss = 0.0653\n",
      "Iteration 760, loss = 0.0253\n",
      "Iteration 780, loss = 0.0005\n",
      "Iteration 800, loss = 0.2532\n",
      "Iteration 820, loss = 0.0022\n",
      "Iteration 0, loss = 0.0121\n",
      "Iteration 20, loss = 0.0119\n",
      "Iteration 40, loss = 0.2507\n",
      "Iteration 60, loss = 0.9958\n",
      "Iteration 80, loss = 0.1711\n",
      "Iteration 100, loss = 0.0049\n",
      "Iteration 120, loss = 0.0167\n",
      "Iteration 140, loss = 0.0001\n",
      "Iteration 160, loss = 0.0376\n",
      "Iteration 180, loss = 0.0000\n",
      "Iteration 200, loss = 0.0001\n",
      "Iteration 220, loss = 0.0083\n",
      "Iteration 240, loss = 0.0912\n",
      "Iteration 260, loss = 0.2278\n",
      "Iteration 280, loss = 0.0001\n",
      "Iteration 300, loss = 0.0854\n",
      "Iteration 320, loss = 0.0660\n",
      "Iteration 340, loss = 0.8728\n",
      "Iteration 360, loss = 0.3325\n",
      "Iteration 380, loss = 0.0000\n",
      "Iteration 400, loss = 0.0677\n",
      "Iteration 420, loss = 0.0048\n",
      "Iteration 440, loss = 0.0072\n",
      "Iteration 460, loss = 0.0044\n",
      "Iteration 480, loss = 0.0011\n",
      "Iteration 500, loss = 0.0095\n",
      "Iteration 520, loss = 0.0218\n",
      "Iteration 540, loss = 0.9305\n",
      "Iteration 560, loss = 0.0189\n",
      "Iteration 580, loss = 0.0818\n",
      "Iteration 600, loss = 0.0413\n",
      "Iteration 620, loss = 0.0121\n",
      "Iteration 640, loss = 0.0006\n",
      "Iteration 660, loss = 0.0058\n",
      "Iteration 680, loss = 0.0357\n",
      "Iteration 700, loss = 0.1553\n",
      "Iteration 720, loss = 0.0075\n",
      "Iteration 740, loss = 0.0063\n",
      "Iteration 760, loss = 0.0028\n",
      "Iteration 780, loss = 0.0051\n",
      "Iteration 800, loss = 0.0030\n",
      "Iteration 820, loss = 0.0097\n",
      "Iteration 0, loss = 0.0025\n",
      "Iteration 20, loss = 0.0205\n",
      "Iteration 40, loss = 0.5614\n",
      "Iteration 60, loss = 0.0351\n",
      "Iteration 80, loss = 0.7309\n",
      "Iteration 100, loss = 0.0100\n",
      "Iteration 120, loss = 0.0109\n",
      "Iteration 140, loss = 0.0531\n",
      "Iteration 160, loss = 0.0415\n",
      "Iteration 180, loss = 0.0936\n",
      "Iteration 200, loss = 0.0013\n",
      "Iteration 220, loss = 0.0109\n",
      "Iteration 240, loss = 0.1114\n",
      "Iteration 260, loss = 0.0554\n",
      "Iteration 280, loss = 0.0006\n",
      "Iteration 300, loss = 0.0010\n",
      "Iteration 320, loss = 0.0150\n",
      "Iteration 340, loss = 0.4847\n",
      "Iteration 360, loss = 0.0038\n",
      "Iteration 380, loss = 0.0384\n",
      "Iteration 400, loss = 0.0194\n",
      "Iteration 420, loss = 0.0030\n",
      "Iteration 440, loss = 0.1333\n",
      "Iteration 460, loss = 0.0047\n",
      "Iteration 480, loss = 0.0007\n",
      "Iteration 500, loss = 0.0160\n",
      "Iteration 520, loss = 0.0007\n",
      "Iteration 540, loss = 0.2319\n",
      "Iteration 560, loss = 0.0000\n",
      "Iteration 580, loss = 0.0167\n",
      "Iteration 600, loss = 0.0000\n",
      "Iteration 620, loss = 0.0064\n",
      "Iteration 640, loss = 0.0277\n",
      "Iteration 660, loss = 0.0024\n",
      "Iteration 680, loss = 0.5897\n",
      "Iteration 700, loss = 0.0054\n",
      "Iteration 720, loss = 0.3967\n",
      "Iteration 740, loss = 0.7826\n",
      "Iteration 760, loss = 0.0139\n",
      "Iteration 780, loss = 0.0026\n",
      "Iteration 800, loss = 0.0029\n",
      "Iteration 820, loss = 0.0005\n",
      "Iteration 0, loss = 0.0160\n",
      "Iteration 20, loss = 0.0353\n",
      "Iteration 40, loss = 0.0261\n",
      "Iteration 60, loss = 0.0037\n",
      "Iteration 80, loss = 0.0070\n",
      "Iteration 100, loss = 0.0016\n",
      "Iteration 120, loss = 0.0011\n",
      "Iteration 140, loss = 0.0238\n",
      "Iteration 160, loss = 0.0046\n",
      "Iteration 180, loss = 0.0833\n",
      "Iteration 200, loss = 0.0149\n",
      "Iteration 220, loss = 0.0005\n",
      "Iteration 240, loss = 0.0003\n",
      "Iteration 260, loss = 0.0006\n",
      "Iteration 280, loss = 0.0006\n",
      "Iteration 300, loss = 0.0412\n",
      "Iteration 320, loss = 0.0008\n",
      "Iteration 340, loss = 0.0230\n",
      "Iteration 360, loss = 0.4359\n",
      "Iteration 380, loss = 1.0263\n",
      "Iteration 400, loss = 0.4417\n",
      "Iteration 420, loss = 0.0009\n",
      "Iteration 440, loss = 0.0015\n",
      "Iteration 460, loss = 0.0141\n",
      "Iteration 480, loss = 0.0247\n",
      "Iteration 500, loss = 0.0000\n",
      "Iteration 520, loss = 0.0006\n",
      "Iteration 540, loss = 0.0001\n",
      "Iteration 560, loss = 0.7230\n",
      "Iteration 580, loss = 0.0693\n",
      "Iteration 600, loss = 0.0190\n",
      "Iteration 620, loss = 0.0074\n",
      "Iteration 640, loss = 0.0578\n",
      "Iteration 660, loss = 0.3533\n",
      "Iteration 680, loss = 0.0147\n",
      "Iteration 700, loss = 0.0022\n",
      "Iteration 720, loss = 0.0035\n",
      "Iteration 740, loss = 0.0099\n",
      "Iteration 760, loss = 0.0001\n",
      "Iteration 780, loss = 0.0291\n",
      "Iteration 800, loss = 0.0104\n",
      "Iteration 820, loss = 0.0384\n",
      "Iteration 0, loss = 0.0049\n",
      "Iteration 20, loss = 0.0006\n",
      "Iteration 40, loss = 0.0002\n",
      "Iteration 60, loss = 0.0005\n",
      "Iteration 80, loss = 0.2974\n",
      "Iteration 100, loss = 0.1047\n",
      "Iteration 120, loss = 0.2406\n",
      "Iteration 140, loss = 0.0090\n",
      "Iteration 160, loss = 0.0035\n",
      "Iteration 180, loss = 0.0016\n",
      "Iteration 200, loss = 0.0003\n",
      "Iteration 220, loss = 0.0000\n",
      "Iteration 240, loss = 0.3314\n",
      "Iteration 260, loss = 0.0000\n",
      "Iteration 280, loss = 0.0055\n",
      "Iteration 300, loss = 0.1116\n",
      "Iteration 320, loss = 0.3881\n",
      "Iteration 340, loss = 0.0825\n",
      "Iteration 360, loss = 0.1574\n",
      "Iteration 380, loss = 0.4711\n",
      "Iteration 400, loss = 0.1631\n",
      "Iteration 420, loss = 0.9939\n",
      "Iteration 440, loss = 0.0091\n",
      "Iteration 460, loss = 0.0325\n",
      "Iteration 480, loss = 0.0004\n",
      "Iteration 500, loss = 0.0100\n",
      "Iteration 520, loss = 0.0056\n",
      "Iteration 540, loss = 0.0010\n",
      "Iteration 560, loss = 0.0001\n",
      "Iteration 580, loss = 0.0000\n",
      "Iteration 600, loss = 0.4416\n",
      "Iteration 620, loss = 0.0268\n",
      "Iteration 640, loss = 0.0088\n",
      "Iteration 660, loss = 0.0049\n",
      "Iteration 680, loss = 0.0020\n",
      "Iteration 700, loss = 0.0216\n",
      "Iteration 720, loss = 0.0236\n",
      "Iteration 740, loss = 0.0045\n",
      "Iteration 760, loss = 0.0147\n",
      "Iteration 780, loss = 0.0328\n",
      "Iteration 800, loss = 0.0829\n",
      "Iteration 820, loss = 0.0049\n",
      "Iteration 0, loss = 0.0375\n",
      "Iteration 20, loss = 0.0116\n",
      "Iteration 40, loss = 0.7641\n",
      "Iteration 60, loss = 0.0012\n",
      "Iteration 80, loss = 0.0054\n",
      "Iteration 100, loss = 0.0381\n",
      "Iteration 120, loss = 0.0065\n",
      "Iteration 140, loss = 0.0002\n",
      "Iteration 160, loss = 0.0032\n",
      "Iteration 180, loss = 0.0400\n",
      "Iteration 200, loss = 0.0000\n",
      "Iteration 220, loss = 0.0187\n",
      "Iteration 240, loss = 0.0012\n",
      "Iteration 260, loss = 0.0673\n",
      "Iteration 280, loss = 0.0078\n",
      "Iteration 300, loss = 0.0857\n",
      "Iteration 320, loss = 0.0218\n",
      "Iteration 340, loss = 0.0713\n",
      "Iteration 360, loss = 0.0010\n",
      "Iteration 380, loss = 0.0000\n",
      "Iteration 400, loss = 0.0473\n",
      "Iteration 420, loss = 0.2496\n",
      "Iteration 440, loss = 0.6463\n",
      "Iteration 460, loss = 0.0027\n",
      "Iteration 480, loss = 0.0008\n",
      "Iteration 500, loss = 0.0051\n",
      "Iteration 520, loss = 0.0282\n",
      "Iteration 540, loss = 0.0000\n",
      "Iteration 560, loss = 0.0119\n",
      "Iteration 580, loss = 0.2850\n",
      "Iteration 600, loss = 0.0065\n",
      "Iteration 620, loss = 0.1459\n",
      "Iteration 640, loss = 0.6070\n",
      "Iteration 660, loss = 0.0214\n",
      "Iteration 680, loss = 0.0459\n",
      "Iteration 700, loss = 0.0003\n",
      "Iteration 720, loss = 0.1030\n",
      "Iteration 740, loss = 0.0008\n",
      "Iteration 760, loss = 0.0102\n",
      "Iteration 780, loss = 0.0014\n",
      "Iteration 800, loss = 0.0003\n",
      "Iteration 820, loss = 0.0192\n",
      "Iteration 0, loss = 0.0307\n",
      "Iteration 20, loss = 0.0001\n",
      "Iteration 40, loss = 0.0005\n",
      "Iteration 60, loss = 0.3199\n",
      "Iteration 80, loss = 0.1001\n",
      "Iteration 100, loss = 0.1526\n",
      "Iteration 120, loss = 0.0025\n",
      "Iteration 140, loss = 0.0049\n",
      "Iteration 160, loss = 0.0021\n",
      "Iteration 180, loss = 0.1526\n",
      "Iteration 200, loss = 0.0001\n",
      "Iteration 220, loss = 0.0003\n",
      "Iteration 240, loss = 0.3821\n",
      "Iteration 260, loss = 0.0026\n",
      "Iteration 280, loss = 0.0040\n",
      "Iteration 300, loss = 0.0303\n",
      "Iteration 320, loss = 0.0025\n",
      "Iteration 340, loss = 0.0005\n",
      "Iteration 360, loss = 0.0014\n",
      "Iteration 380, loss = 0.1206\n",
      "Iteration 400, loss = 0.7209\n",
      "Iteration 420, loss = 0.0247\n",
      "Iteration 440, loss = 0.0003\n",
      "Iteration 460, loss = 0.0213\n",
      "Iteration 480, loss = 0.0050\n",
      "Iteration 500, loss = 0.0022\n",
      "Iteration 520, loss = 0.0005\n",
      "Iteration 540, loss = 0.8107\n",
      "Iteration 560, loss = 0.0000\n",
      "Iteration 580, loss = 0.0027\n",
      "Iteration 600, loss = 0.0007\n",
      "Iteration 620, loss = 0.0015\n",
      "Iteration 640, loss = 0.0061\n",
      "Iteration 660, loss = 0.1047\n",
      "Iteration 680, loss = 0.0000\n",
      "Iteration 700, loss = 0.0005\n",
      "Iteration 720, loss = 0.0000\n",
      "Iteration 740, loss = 0.1390\n",
      "Iteration 760, loss = 0.0000\n",
      "Iteration 780, loss = 0.0000\n",
      "Iteration 800, loss = 0.0076\n",
      "Iteration 820, loss = 0.0184\n",
      "Iteration 0, loss = 0.0292\n",
      "Iteration 20, loss = 0.0022\n",
      "Iteration 40, loss = 0.0020\n",
      "Iteration 60, loss = 0.0021\n",
      "Iteration 80, loss = 0.0177\n",
      "Iteration 100, loss = 0.0035\n",
      "Iteration 120, loss = 0.0110\n",
      "Iteration 140, loss = 0.0000\n",
      "Iteration 160, loss = 0.1769\n",
      "Iteration 180, loss = 0.0011\n",
      "Iteration 200, loss = 0.0000\n",
      "Iteration 220, loss = 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 240, loss = 0.0147\n",
      "Iteration 260, loss = 0.0322\n",
      "Iteration 280, loss = 0.0004\n",
      "Iteration 300, loss = 0.0000\n",
      "Iteration 320, loss = 0.0002\n",
      "Iteration 340, loss = 0.0080\n",
      "Iteration 360, loss = 0.7186\n",
      "Iteration 380, loss = 0.0000\n",
      "Iteration 400, loss = 0.2053\n",
      "Iteration 420, loss = 0.0324\n",
      "Iteration 440, loss = 0.0009\n",
      "Iteration 460, loss = 0.0188\n",
      "Iteration 480, loss = 0.0050\n",
      "Iteration 500, loss = 0.0053\n",
      "Iteration 520, loss = 0.0073\n",
      "Iteration 540, loss = 0.0032\n",
      "Iteration 560, loss = 0.0671\n",
      "Iteration 580, loss = 0.0031\n",
      "Iteration 600, loss = 0.0000\n",
      "Iteration 620, loss = 0.2548\n",
      "Iteration 640, loss = 0.3109\n",
      "Iteration 660, loss = 0.4623\n",
      "Iteration 680, loss = 0.0000\n",
      "Iteration 700, loss = 0.0036\n",
      "Iteration 720, loss = 0.0470\n",
      "Iteration 740, loss = 0.2274\n",
      "Iteration 760, loss = 0.1776\n",
      "Iteration 780, loss = 0.0000\n",
      "Iteration 800, loss = 0.6147\n",
      "Iteration 820, loss = 0.0581\n",
      "Iteration 0, loss = 0.0001\n",
      "Iteration 20, loss = 0.0091\n",
      "Iteration 40, loss = 0.0001\n",
      "Iteration 60, loss = 0.0383\n",
      "Iteration 80, loss = 0.0301\n",
      "Iteration 100, loss = 0.0087\n",
      "Iteration 120, loss = 0.1131\n",
      "Iteration 140, loss = 0.0003\n",
      "Iteration 160, loss = 0.0032\n",
      "Iteration 180, loss = 0.0282\n",
      "Iteration 200, loss = 0.0022\n",
      "Iteration 220, loss = 0.0008\n",
      "Iteration 240, loss = 0.1469\n",
      "Iteration 260, loss = 0.4000\n",
      "Iteration 280, loss = 0.0134\n",
      "Iteration 300, loss = 0.0057\n",
      "Iteration 320, loss = 0.0151\n",
      "Iteration 340, loss = 0.0006\n",
      "Iteration 360, loss = 0.0058\n",
      "Iteration 380, loss = 0.0023\n",
      "Iteration 400, loss = 0.0302\n",
      "Iteration 420, loss = 0.0029\n",
      "Iteration 440, loss = 0.0166\n",
      "Iteration 460, loss = 0.0079\n",
      "Iteration 480, loss = 0.0073\n",
      "Iteration 500, loss = 0.0025\n",
      "Iteration 520, loss = 0.1171\n",
      "Iteration 540, loss = 0.0002\n",
      "Iteration 560, loss = 0.0089\n",
      "Iteration 580, loss = 0.7460\n",
      "Iteration 600, loss = 0.0023\n",
      "Iteration 620, loss = 0.0002\n",
      "Iteration 640, loss = 0.0006\n",
      "Iteration 660, loss = 0.0453\n",
      "Iteration 680, loss = 0.1139\n",
      "Iteration 700, loss = 0.0092\n",
      "Iteration 720, loss = 0.0144\n",
      "Iteration 740, loss = 0.0008\n",
      "Iteration 760, loss = 0.0136\n",
      "Iteration 780, loss = 0.0000\n",
      "Iteration 800, loss = 0.0008\n",
      "Iteration 820, loss = 0.0413\n",
      "Iteration 0, loss = 0.3122\n",
      "Iteration 20, loss = 0.0806\n",
      "Iteration 40, loss = 0.0319\n",
      "Iteration 60, loss = 0.0124\n",
      "Iteration 80, loss = 0.0000\n",
      "Iteration 100, loss = 1.8361\n",
      "Iteration 120, loss = 0.0932\n",
      "Iteration 140, loss = 0.2281\n",
      "Iteration 160, loss = 0.0238\n",
      "Iteration 180, loss = 0.0027\n",
      "Iteration 200, loss = 0.0000\n",
      "Iteration 220, loss = 0.0000\n",
      "Iteration 240, loss = 0.0052\n",
      "Iteration 260, loss = 0.0113\n",
      "Iteration 280, loss = 0.0192\n",
      "Iteration 300, loss = 0.0002\n",
      "Iteration 320, loss = 0.0016\n",
      "Iteration 340, loss = 0.1611\n",
      "Iteration 360, loss = 0.0101\n",
      "Iteration 380, loss = 0.0000\n",
      "Iteration 400, loss = 0.0001\n",
      "Iteration 420, loss = 0.0072\n",
      "Iteration 440, loss = 0.0380\n",
      "Iteration 460, loss = 0.0079\n",
      "Iteration 480, loss = 0.0282\n",
      "Iteration 500, loss = 0.0013\n",
      "Iteration 520, loss = 0.0000\n",
      "Iteration 540, loss = 0.0007\n",
      "Iteration 560, loss = 0.0004\n",
      "Iteration 580, loss = 0.0085\n",
      "Iteration 600, loss = 0.0315\n",
      "Iteration 620, loss = 0.0109\n",
      "Iteration 640, loss = 0.0014\n",
      "Iteration 660, loss = 0.6157\n",
      "Iteration 680, loss = 0.0113\n",
      "Iteration 700, loss = 0.3336\n",
      "Iteration 720, loss = 0.0015\n",
      "Iteration 740, loss = 0.4675\n",
      "Iteration 760, loss = 0.0025\n",
      "Iteration 780, loss = 0.0008\n",
      "Iteration 800, loss = 0.0014\n",
      "Iteration 820, loss = 0.1778\n",
      "Iteration 0, loss = 0.5231\n",
      "Iteration 20, loss = 0.0052\n",
      "Iteration 40, loss = 0.0038\n",
      "Iteration 60, loss = 0.0159\n",
      "Iteration 80, loss = 0.0006\n",
      "Iteration 100, loss = 0.0011\n",
      "Iteration 120, loss = 0.2282\n",
      "Iteration 140, loss = 0.0038\n",
      "Iteration 160, loss = 0.0000\n",
      "Iteration 180, loss = 0.0063\n",
      "Iteration 200, loss = 0.0000\n",
      "Iteration 220, loss = 0.0018\n",
      "Iteration 240, loss = 0.0020\n",
      "Iteration 260, loss = 0.0840\n",
      "Iteration 280, loss = 0.0039\n",
      "Iteration 300, loss = 0.0016\n",
      "Iteration 320, loss = 0.0084\n",
      "Iteration 340, loss = 0.0001\n",
      "Iteration 360, loss = 0.0010\n",
      "Iteration 380, loss = 0.0004\n",
      "Iteration 400, loss = 0.0027\n",
      "Iteration 420, loss = 0.0000\n",
      "Iteration 440, loss = 0.1166\n",
      "Iteration 460, loss = 0.0002\n",
      "Iteration 480, loss = 0.0012\n",
      "Iteration 500, loss = 0.0004\n",
      "Iteration 520, loss = 0.0111\n",
      "Iteration 540, loss = 0.0202\n",
      "Iteration 560, loss = 0.0000\n",
      "Iteration 580, loss = 0.0043\n",
      "Iteration 600, loss = 0.1918\n",
      "Iteration 620, loss = 0.0040\n",
      "Iteration 640, loss = 0.0102\n",
      "Iteration 660, loss = 0.0014\n",
      "Iteration 680, loss = 0.0531\n",
      "Iteration 700, loss = 0.5399\n",
      "Iteration 720, loss = 0.0040\n",
      "Iteration 740, loss = 0.0216\n",
      "Iteration 760, loss = 0.0054\n",
      "Iteration 780, loss = 0.0002\n",
      "Iteration 800, loss = 0.0189\n",
      "Iteration 820, loss = 0.0007\n",
      "Iteration 0, loss = 0.0002\n",
      "Iteration 20, loss = 0.0279\n",
      "Iteration 40, loss = 0.0000\n",
      "Iteration 60, loss = 0.0008\n",
      "Iteration 80, loss = 0.0097\n",
      "Iteration 100, loss = 0.9181\n",
      "Iteration 120, loss = 0.0065\n",
      "Iteration 140, loss = 0.0011\n",
      "Iteration 160, loss = 0.0905\n",
      "Iteration 180, loss = 0.0972\n",
      "Iteration 200, loss = 0.0037\n",
      "Iteration 220, loss = 0.0200\n",
      "Iteration 240, loss = 0.0039\n",
      "Iteration 260, loss = 0.0302\n",
      "Iteration 280, loss = 0.0000\n",
      "Iteration 300, loss = 0.0000\n",
      "Iteration 320, loss = 0.0003\n",
      "Iteration 340, loss = 0.0023\n",
      "Iteration 360, loss = 0.0085\n",
      "Iteration 380, loss = 0.1130\n",
      "Iteration 400, loss = 0.0007\n",
      "Iteration 420, loss = 0.0019\n",
      "Iteration 440, loss = 0.0010\n",
      "Iteration 460, loss = 0.0115\n",
      "Iteration 480, loss = 0.0045\n",
      "Iteration 500, loss = 0.0071\n",
      "Iteration 520, loss = 0.0264\n",
      "Iteration 540, loss = 0.0102\n",
      "Iteration 560, loss = 0.0008\n",
      "Iteration 580, loss = 0.0336\n",
      "Iteration 600, loss = 0.0072\n",
      "Iteration 620, loss = 0.0001\n",
      "Iteration 640, loss = 0.0023\n",
      "Iteration 660, loss = 0.0081\n",
      "Iteration 680, loss = 0.0000\n",
      "Iteration 700, loss = 0.0090\n",
      "Iteration 720, loss = 0.0031\n",
      "Iteration 740, loss = 0.0144\n",
      "Iteration 760, loss = 0.0012\n",
      "Iteration 780, loss = 0.0036\n",
      "Iteration 800, loss = 0.0000\n",
      "Iteration 820, loss = 0.0014\n",
      "Iteration 0, loss = 0.1309\n",
      "Iteration 20, loss = 0.1916\n",
      "Iteration 40, loss = 0.0001\n",
      "Iteration 60, loss = 0.0053\n",
      "Iteration 80, loss = 0.0005\n",
      "Iteration 100, loss = 0.0004\n",
      "Iteration 120, loss = 0.0001\n",
      "Iteration 140, loss = 0.0112\n",
      "Iteration 160, loss = 0.0230\n",
      "Iteration 180, loss = 0.1200\n",
      "Iteration 200, loss = 0.0020\n",
      "Iteration 220, loss = 0.0562\n",
      "Iteration 240, loss = 0.0035\n",
      "Iteration 260, loss = 0.0083\n",
      "Iteration 280, loss = 0.0001\n",
      "Iteration 300, loss = 0.1770\n",
      "Iteration 320, loss = 0.0002\n",
      "Iteration 340, loss = 0.0017\n",
      "Iteration 360, loss = 0.0010\n",
      "Iteration 380, loss = 0.0000\n",
      "Iteration 400, loss = 0.0023\n",
      "Iteration 420, loss = 0.0005\n",
      "Iteration 440, loss = 0.0060\n",
      "Iteration 460, loss = 0.0000\n",
      "Iteration 480, loss = 0.2155\n",
      "Iteration 500, loss = 0.0002\n",
      "Iteration 520, loss = 0.0039\n",
      "Iteration 540, loss = 0.0011\n",
      "Iteration 560, loss = 0.0003\n",
      "Iteration 580, loss = 0.2881\n",
      "Iteration 600, loss = 0.0007\n",
      "Iteration 620, loss = 0.1619\n",
      "Iteration 640, loss = 0.1154\n",
      "Iteration 660, loss = 0.2532\n",
      "Iteration 680, loss = 0.3228\n",
      "Iteration 700, loss = 0.5311\n",
      "Iteration 720, loss = 0.1502\n",
      "Iteration 740, loss = 0.0917\n",
      "Iteration 760, loss = 0.0219\n",
      "Iteration 780, loss = 0.1218\n",
      "Iteration 800, loss = 0.1738\n",
      "Iteration 820, loss = 0.0008\n",
      "Iteration 0, loss = 0.0104\n",
      "Iteration 20, loss = 0.0001\n",
      "Iteration 40, loss = 0.0000\n",
      "Iteration 60, loss = 0.0011\n",
      "Iteration 80, loss = 0.0042\n",
      "Iteration 100, loss = 0.0067\n",
      "Iteration 120, loss = 0.0009\n",
      "Iteration 140, loss = 0.0003\n",
      "Iteration 160, loss = 0.0074\n",
      "Iteration 180, loss = 0.0028\n",
      "Iteration 200, loss = 0.0246\n",
      "Iteration 220, loss = 0.0004\n",
      "Iteration 240, loss = 0.0022\n",
      "Iteration 260, loss = 0.0039\n",
      "Iteration 280, loss = 0.0003\n",
      "Iteration 300, loss = 0.0018\n",
      "Iteration 320, loss = 0.0059\n",
      "Iteration 340, loss = 0.0606\n",
      "Iteration 360, loss = 0.0102\n",
      "Iteration 380, loss = 0.0070\n",
      "Iteration 400, loss = 0.0157\n",
      "Iteration 420, loss = 0.0020\n",
      "Iteration 440, loss = 0.0630\n",
      "Iteration 460, loss = 0.0006\n",
      "Iteration 480, loss = 0.0008\n",
      "Iteration 500, loss = 0.0000\n",
      "Iteration 520, loss = 0.0000\n",
      "Iteration 540, loss = 0.0002\n",
      "Iteration 560, loss = 0.0279\n",
      "Iteration 580, loss = 0.0278\n",
      "Iteration 600, loss = 0.3411\n",
      "Iteration 620, loss = 0.0010\n",
      "Iteration 640, loss = 0.0281\n",
      "Iteration 660, loss = 0.0080\n",
      "Iteration 680, loss = 0.0018\n",
      "Iteration 700, loss = 0.1771\n",
      "Iteration 720, loss = 0.0000\n",
      "Iteration 740, loss = 0.0000\n",
      "Iteration 760, loss = 0.7036\n",
      "Iteration 780, loss = 0.0020\n",
      "Iteration 800, loss = 0.0221\n",
      "Iteration 820, loss = 0.0000\n",
      "Iteration 0, loss = 0.0097\n",
      "Iteration 20, loss = 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40, loss = 0.6546\n",
      "Iteration 60, loss = 0.0000\n",
      "Iteration 80, loss = 0.0005\n",
      "Iteration 100, loss = 0.0000\n",
      "Iteration 120, loss = 0.0092\n",
      "Iteration 140, loss = 0.0004\n",
      "Iteration 160, loss = 0.3651\n",
      "Iteration 180, loss = 0.0005\n",
      "Iteration 200, loss = 0.1801\n",
      "Iteration 220, loss = 0.0007\n",
      "Iteration 240, loss = 0.0017\n",
      "Iteration 260, loss = 0.0001\n",
      "Iteration 280, loss = 0.0001\n",
      "Iteration 300, loss = 0.0119\n",
      "Iteration 320, loss = 0.0000\n",
      "Iteration 340, loss = 0.0076\n",
      "Iteration 360, loss = 0.0000\n",
      "Iteration 380, loss = 0.0005\n",
      "Iteration 400, loss = 0.0029\n",
      "Iteration 420, loss = 0.0040\n",
      "Iteration 440, loss = 0.0249\n",
      "Iteration 460, loss = 0.0001\n",
      "Iteration 480, loss = 0.0009\n",
      "Iteration 500, loss = 0.0002\n",
      "Iteration 520, loss = 0.0941\n",
      "Iteration 540, loss = 0.0034\n",
      "Iteration 560, loss = 0.0006\n",
      "Iteration 580, loss = 0.0001\n",
      "Iteration 600, loss = 0.0000\n",
      "Iteration 620, loss = 0.0217\n",
      "Iteration 640, loss = 0.0003\n",
      "Iteration 660, loss = 0.0029\n",
      "Iteration 680, loss = 0.0013\n",
      "Iteration 700, loss = 0.0000\n",
      "Iteration 720, loss = 0.0077\n",
      "Iteration 740, loss = 0.0001\n",
      "Iteration 760, loss = 0.0001\n",
      "Iteration 780, loss = 0.0152\n",
      "Iteration 800, loss = 0.0104\n",
      "Iteration 820, loss = 0.0006\n",
      "Iteration 0, loss = 0.0088\n",
      "Iteration 20, loss = 0.3899\n",
      "Iteration 40, loss = 0.0922\n",
      "Iteration 60, loss = 0.0170\n",
      "Iteration 80, loss = 0.0006\n",
      "Iteration 100, loss = 0.0001\n",
      "Iteration 120, loss = 0.0000\n",
      "Iteration 140, loss = 0.0003\n",
      "Iteration 160, loss = 0.0000\n",
      "Iteration 180, loss = 0.0010\n",
      "Iteration 200, loss = 0.0004\n",
      "Iteration 220, loss = 0.0853\n",
      "Iteration 240, loss = 0.0004\n",
      "Iteration 260, loss = 0.0002\n",
      "Iteration 280, loss = 0.0511\n",
      "Iteration 300, loss = 0.0001\n",
      "Iteration 320, loss = 0.9046\n",
      "Iteration 340, loss = 0.0272\n",
      "Iteration 360, loss = 0.0000\n",
      "Iteration 380, loss = 0.0000\n",
      "Iteration 400, loss = 0.0001\n",
      "Iteration 420, loss = 0.0003\n",
      "Iteration 440, loss = 0.0003\n",
      "Iteration 460, loss = 0.0055\n",
      "Iteration 480, loss = 0.0239\n",
      "Iteration 500, loss = 0.7864\n",
      "Iteration 520, loss = 0.0050\n",
      "Iteration 540, loss = 0.0008\n",
      "Iteration 560, loss = 0.0005\n",
      "Iteration 580, loss = 0.0007\n",
      "Iteration 600, loss = 0.0337\n",
      "Iteration 620, loss = 0.0151\n",
      "Iteration 640, loss = 0.1013\n",
      "Iteration 660, loss = 0.0984\n",
      "Iteration 680, loss = 0.0014\n",
      "Iteration 700, loss = 0.5457\n",
      "Iteration 720, loss = 0.3957\n",
      "Iteration 740, loss = 0.0003\n",
      "Iteration 760, loss = 0.0001\n",
      "Iteration 780, loss = 0.0096\n",
      "Iteration 800, loss = 0.0185\n",
      "Iteration 820, loss = 0.4418\n",
      "Iteration 0, loss = 0.0021\n",
      "Iteration 20, loss = 0.1077\n",
      "Iteration 40, loss = 0.0024\n",
      "Iteration 60, loss = 0.0029\n",
      "Iteration 80, loss = 0.0016\n",
      "Iteration 100, loss = 0.0523\n",
      "Iteration 120, loss = 0.0815\n",
      "Iteration 140, loss = 0.0003\n",
      "Iteration 160, loss = 0.2014\n",
      "Iteration 180, loss = 0.0006\n",
      "Iteration 200, loss = 0.0060\n",
      "Iteration 220, loss = 0.0474\n",
      "Iteration 240, loss = 0.0000\n",
      "Iteration 260, loss = 0.0013\n",
      "Iteration 280, loss = 0.0000\n",
      "Iteration 300, loss = 0.0002\n",
      "Iteration 320, loss = 0.0004\n",
      "Iteration 340, loss = 0.0003\n",
      "Iteration 360, loss = 0.0002\n",
      "Iteration 380, loss = 0.0142\n",
      "Iteration 400, loss = 0.0004\n",
      "Iteration 420, loss = 0.0548\n",
      "Iteration 440, loss = 0.0126\n",
      "Iteration 460, loss = 0.0000\n",
      "Iteration 480, loss = 0.0001\n",
      "Iteration 500, loss = 0.0001\n",
      "Iteration 520, loss = 0.0001\n",
      "Iteration 540, loss = 0.0489\n",
      "Iteration 560, loss = 0.0059\n",
      "Iteration 580, loss = 0.0000\n",
      "Iteration 600, loss = 0.7353\n",
      "Iteration 620, loss = 0.7291\n",
      "Iteration 640, loss = 0.9901\n",
      "Iteration 660, loss = 0.1567\n",
      "Iteration 680, loss = 0.0062\n",
      "Iteration 700, loss = 0.4968\n",
      "Iteration 720, loss = 0.0035\n",
      "Iteration 740, loss = 0.0000\n",
      "Iteration 760, loss = 0.0005\n",
      "Iteration 780, loss = 0.8358\n",
      "Iteration 800, loss = 0.1937\n",
      "Iteration 820, loss = 0.0129\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "model = ConvNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "train(model, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model = model.to(device=device)\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 611 / 1040 correct (58.75)\n",
      "Got 701 / 1040 correct (67.40)\n",
      "Got 710 / 1040 correct (68.27)\n",
      "Got 696 / 1040 correct (66.92)\n",
      "Got 710 / 1040 correct (68.27)\n",
      "Got 686 / 1040 correct (65.96)\n",
      "Got 715 / 1040 correct (68.75)\n",
      "Got 693 / 1040 correct (66.63)\n",
      "Got 694 / 1040 correct (66.73)\n",
      "Got 672 / 1040 correct (64.62)\n",
      "Got 688 / 1040 correct (66.15)\n",
      "Got 685 / 1040 correct (65.87)\n",
      "Got 662 / 1040 correct (63.65)\n",
      "Got 696 / 1040 correct (66.92)\n",
      "Got 676 / 1040 correct (65.00)\n"
     ]
    }
   ],
   "source": [
    "accs = list()\n",
    "for i in range(0,30,2):\n",
    "    model = ConvNet()\n",
    "    model.load_state_dict(torch.load(os.path.join('/home/max/saved_data/classifier2/model_epoch'+str(i)+'.pth')))\n",
    "    acc = check_accuracy_part(test_loader, model)\n",
    "    accs.append(acc)\n",
    "\n",
    "accs = np.array(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join('/home/max/saved_data/classifier2'),accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
